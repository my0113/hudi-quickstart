## linux env config
# JAVA_HOME=/usr/local/java/jdk1.8.0_101
# HADOOP_CONF_DIR=/usr/hdp/current/hadoop-client/etc/hadoop
# SPARK_HOME=/usr/hdp/current/spark2-client
## windows env config
JAVA_HOME=C:/Program Files/Java/jdk1.8.0_271
HADOOP_HOME=D:/softs/developer/Apache/hadoop-3.1.0
HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
SPARK_HOME=D:/softs/developer/Apache/spark-2.4.6-bin-hadoop2.7
SPARK_PRINT_LAUNCH_COMMAND=1
## spark config
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.sql.hive.convertMetastoreParquet=false
# spark.master=local[2]
spark.app.name=App
hadoop.home.dir=${HADOOP_HOME}
## other config
user.name=hadoop
default.charset=UTF-8
app.basePath=hdfs://node01:9820
