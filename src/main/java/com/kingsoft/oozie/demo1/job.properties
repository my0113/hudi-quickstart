nameNode=hdfs://node01:9820
jobTracker=node01:8032
queueName=default
oozieDir=apps/oozie
oozieEtlDir=apps/etl/script
sparkOpts=--driver-memory 512m --executor-memory 1g --executor-cores 1 --queue=${queueName}
arg1=10

# 使用oozie的system share lib
oozie.use.system.libpath=true
# oozie额外依赖jar的目录（位于HDFS中）
oozie.libpath=${nameNode}/${oozieDir}/lib/
# workflow.xml位于HDFS上的路径
workflowAppUri=${nameNode}/${oozieEtlDir}/demo1/wf

# coordinator.xml位于HDFS上的路径
oozie.coord.application.path=${nameNode}/${oozieEtlDir}/demo1/coord
# 从1970年开始
start=1970-01-01T00:00+0800
# 每天23点1分执行定时任务
freq=1 23 * * *
# 到2099年结束
end=2099-12-31T23:59+0800